import matplotlib.pyplot as plt
import torch
import torchvision

from torch import nn
from torchvision import transforms

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

def set_seeds(seed=42):
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)

# 1. get pretrained weight for ViT.Base
pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT

# 2. setup a ViT model instance with pretrained weights
pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights).to(device)

# 3. freeze the base parameters
for parameter in pretrained_vit.parameters():
  parameter.requires_grad = False

# 4. change the classifier head
class_names = ["benign", "malignant"]

set_seeds()
pretrained_vit.heads = nn.Linear(in_features=768, out_features=len(class_names)).to(device)
#pretrained_vit # uncomment for model output

from torchinfo import summary

#print a summary using torchinfo (uncomment for actual output)
summary(model=pretrained_vit,
        input_size=(32, 3, 224, 224),
        col_names=["input_size", "output_size", "num_params", "trainable"],
        col_width=20,
        row_settings=["var_names"])



# setup directory path to train and test image
train_dir = "B:\\Cancer\\BreaKHis 400X\\BreaKHis 400X\\train"
test_dir = "B:\\Cancer\\BreaKHis 400X\\BreaKHis 400X\\test"

# get automatic transforms from pretrained vit weights
pretrained_vit_transforms = pretrained_vit_weights.transforms()
print(pretrained_vit_transforms)

# Create optimizer and loss function
optimizer = torch.optim.Adam(params=pretrained_vit.parameters(), lr=1e-3)
loss_fn = torch.nn.CrossEntropyLoss()

# transformer si ready. now we can turn images into dataloaders using the create_dataloaders()
import os
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

NUM_WORKERS = os.cpu_count()

def create_dataloaders(
    train_dir: str,
    test_dir: str,
    transform: transforms.Compose,
    batch_size: int,
    num_workers: int=NUM_WORKERS
):
    # sue ImageFolder to create dataset
    train_data = datasets.ImageFolder(train_dir, transform=transform)
    test_data = datasets.ImageFolder(test_dir, transform=transform)

    # set class names
    class_names = train_data.classes

    # turn images into data loaders
    train_dataloader = DataLoader(
        train_data,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
    )
    test_dataloader = DataLoader(
        test_data,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
    )
    return train_dataloader, test_dataloader, class_names

# setup dataloaders
train_dataloader_pretrained, test_dataloader_pretrained, class_names = create_dataloaders(
    train_dir,
    test_dir,
    transform=pretrained_vit_transforms,
    batch_size=500,
    num_workers=0
)

from tqdm.auto import tqdm

def train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device):
    results = {"train_loss": [], "train_acc": [], "test_loss": [], "test_acc": []}

    model.to(device)
    for epoch in range(epochs):
        print(f"Epoch {epoch+1}/{epochs}")
        model.train()
        train_loss, train_acc = 0, 0

        for X, y in tqdm(train_dataloader, desc="Training"):
            X, y = X.to(device), y.to(device)

            # Forward pass
            y_logits = model(X)
            y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)

            loss = loss_fn(y_logits, y)
            train_loss += loss.item()
            train_acc += (y_pred == y).sum().item() / len(y)

            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        # calculate avg  loss and acc
        train_loss /= len(train_dataloader)
        train_acc /= len(train_dataloader)

        # test phase
        model.eval()
        with torch.inference_mode():
            test_loss, test_acc = 0, 0
            for X_test, y_test in tqdm(test_dataloader, desc="Testing"):
                X_test, y_test = X_test.to(device), y_test.to(device)
                test_logits = model(X_test)
                test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)

                test_loss += loss_fn(test_logits, y_test).item()
                test_acc += (test_pred == y_test).sum().item() / len(y_test)

            test_loss /= len(test_dataloader)
            test_acc /= len(test_dataloader)

        # lo record
        results["train_loss"].append(train_loss)
        results["train_acc"].append(train_acc)
        results["test_loss"].append(test_loss)
        results["test_acc"].append(test_acc)

        print(f"Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}")
        print(f"Test Loss: {test_loss:.4f} | Acc: {test_acc:.4f}\n")

    return results

# train the classifier head of teh pretrained ViT feature extractor model
#if __name__ == "__main__":
set_seeds()
pretrained_vit_results = train(
            model=pretrained_vit,
            train_dataloader=train_dataloader_pretrained,
            test_dataloader=test_dataloader_pretrained,
            optimizer=optimizer,
            loss_fn=loss_fn,
            epochs=30,
            device=device)


# plot the loss curves
import matplotlib.pyplot as plt


def plot_loss_curves(results):
    """Plots training curves of loss and accuracy."""
    loss = results['train_loss']
    test_loss = results['test_loss']

    accuracy = results['train_acc']
    test_accuracy = results['test_acc']

    epochs = range(len(loss))

    plt.figure(figsize=(12, 5))

    # Plot loss
    plt.subplot(1, 2, 1)
    plt.plot(epochs, loss, label='train_loss')
    plt.plot(epochs, test_loss, label='test_loss')
    plt.title('Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, accuracy, label='train_accuracy')
    plt.plot(epochs, test_accuracy, label='test_accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.show()
plot_loss_curves(pretrained_vit_results)

# make predictions on the test data
import requests

# import function to make prediction on images and plot them
from PIL import Image
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
import time

# get all predictions
def get_all_predictions(model, dataloader, device="cpu"):
    model.eval()
    all_preds = []
    all_labels = []
    all_probs = []

    with torch.inference_mode():
        for X, y in tqdm(dataloader, desc="Predicting on test set"):
            X, y = X.to(device), y.to(device)
            logits = model(X)
            probs = torch.softmax(logits, dim=1)

            all_preds.extend(probs[:, 1].cpu())  
            all_labels.extend(y.cpu())

        return torch.tensor(all_labels), torch.tensor(all_preds)

def evaluate_model(model, dataloader, device="cpu", class_names=["benign", "malignant"]):
    model.eval()
    y_true, y_score = get_all_predictions(model, dataloader, device=device)
    y_pred = (y_score > 0.5).int()

    # initialize metrics
    f1_metric = BinaryF1Score().to(device)
    auroc_metric = BinaryAUROC().to(device)
    cm_metric = BinaryConfusionMatrix().to(device)

    # calculate metrics
    f1 = f1_metric(y_score, y_true)
    auroc = auroc_metric(y_score, y_true)
    cm = cm_metric(y_score, y_true).cpu().numpy()

    print(f"AUROC: {auroc.item():.4f}")
    print(f"F1-Score: {f1.item():.4f}")

    # 显示混淆矩阵
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names,
                yticklabels=class_names)
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title("Confusion Matrix")
    plt.show()

    # 
    from collections import defaultdict
    report = defaultdict(dict)

    tp = cm[1, 1]
    fp = cm[0, 1]
    fn = cm[1, 0]
    tn = cm[0, 0]

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    precision_neg = tn / (tn + fn) if (tn + fn) > 0 else 0
    recall_neg = tn / (tn + fp) if (tn + fp) > 0 else 0
    f1_neg = 2 * (precision_neg * recall_neg) / (precision_neg + recall_neg) if (precision_neg + recall_neg) > 0 else 0

    print("\nManual Classification Report:")
    print(f"{class_names[0]}      precision: {precision_neg:.4f}  recall: {recall_neg:.4f}  f1-score: {f1_neg:.4f}")
    print(f"{class_names[1]}      precision: {precision:.4f}  recall: {recall:.4f}  f1-score: {f1:.4f}")
    print(f"accuracy                          { (tp + tn) / (tp + tn + fp + fn):.4f}")



# 
def predict_and_plot_images_from_folder(model, folder_path, transform=None, class_names=["benign", "malignant"],
                                        device="cpu", num_images=9):
    """
    Predict and plot images from a folder.

    Args:
        model: Trained PyTorch model
        folder_path: Path to folder containing images
        transform: Optional transform for preprocessing
        class_names: List of class names (e.g. ["benign", "malignant"])
        device: Device to run on ("cuda" or "cpu")
        num_images: Number of images to display
    """
    model.eval()
    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.png', '.jpg', '.jpeg'))]
    images_shown = 0.0

    plt.figure(figsize=(15, 10))
    total_time = 0.0

    for img_file in image_files:
        if images_shown >= num_images:
            break

        image_path = os.path.join(folder_path, img_file)
        try:
            img = Image.open(image_path).convert("RGB")
        except Exception as e:
            print(f"无法加载图像 {img_file}: {e}")
            continue

        # Apply transform
        if transform is None:
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
            ])

        transformed_img = transform(img).unsqueeze(0).to(device)

        # Inference
        start_time = time.time()
        model.eval()
        with torch.inference_mode():
            output = model(transformed_img)
            prob = torch.softmax(output, dim=1)
            pred = prob.argmax().item()

        end_time = time.time()
        inference_time = end_time - start_time
        total_time += inference_time

        # Plot
        ax = plt.subplot(num_images // 3 + 1, 3, images_shown + 1)
        ax.imshow(img)
        ax.set_title(f"Pred: {class_names[pred]}\nConfidence: {prob[0][pred]:.2f}", fontsize=10)
        ax.axis("on")

        images_shown += 1
    avg_time = total_time / images_shown if images_shown > 0 else 0
    print(f"\n✅ 总共预测 {images_shown} 张图像")
    print(f"⏱️ 平均推理时间: {avg_time:.3f} 秒/张")

    plt.tight_layout()
    plt.show()

plot_loss_curves(pretrained_vit_results)

# setup custom image path
valid_benign_dir = "B:\\Cancer\\BreaKHis 400X\\BreaKHis 400X\\valid\\benign"
valid_malignant_dir = "B:\\Cancer\\BreaKHis 400X\\BreaKHis 400X\\valid\\malignant"

print("✅ benign image：")
predict_and_plot_images_from_folder(pretrained_vit, valid_benign_dir,
                                        transform=pretrained_vit_transforms,
                                        class_names=class_names,
                                        device=device,
                                        num_images=9)

print("✅ malignant image：")
predict_and_plot_images_from_folder(pretrained_vit, valid_malignant_dir,
                                        transform=pretrained_vit_transforms,
                                        class_names=class_names,
                                        device=device,
                                        num_images=9)



print("\nManual Classification Report:")
print(f"{class_names[0]}      precision: {precision_neg:.4f}  recall: {recall_neg:.4f}  f1-score: {f1_neg:.4f}")
print(f"{class_names[1]}      precision: {precision:.4f}  recall: {recall:.4f}  f1-score: {f1:.4f}")
print(f"accuracy                          { (tp + tn) / (tp + tn + fp + fn):.4f}")
