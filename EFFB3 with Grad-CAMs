import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
import os
from sklearn.utils.class_weight import compute_class_weight
import pandas as pd
from sklearn.model_selection import train_test_split

# ========== PREPARING DATASET ==========
names = ["benign", "malignant"]
# Correct reference to the preprocess_input function for EfficientNetB3

preprocess_input = tf.keras.applications.efficientnet.preprocess_input

# Generate batches of tensor image data with real-time dataaugmentation
train_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)
          #rotation_range=20,
          #horizontal_flip=True,
          #width_shift_range=0.2,
          #height_shift_range=0.2,
          #shear_range=0.5,
          #zoom_range=1.0)
test_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)
valid_gen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)

train_batches = train_gen.flow_from_directory(
  "B:\\Cancer\\BreaKHis 400X\\BreaKHis 400X\\train",
  target_size=(300,300),
  class_mode='binary',
  batch_size=32,
  shuffle=True,
  color_mode="rgb",
  classes=names
)

test_batches = test_gen.flow_from_directory(
  "B:\\Cancer\\BreaKHis 400X\\BreaKHis 400X\\test",
  target_size=(300,300),
  class_mode='binary',
  batch_size=32,
  shuffle=False,
  color_mode="rgb",
  classes=names
)

valid_batches = valid_gen.flow_from_directory(
  "B:\\Cancer\\BreaKHis 400X\\BreaKHis 400X\\valid",
  target_size=(300,300),
  class_mode='binary',
  batch_size=32,
  shuffle=False,
  color_mode="rgb",
  classes=names
)


# Get class names and indices
class_indices = train_batches.class_indices
class_names = list(class_indices.keys())
print("Class names:", class_names)

# Compute class weights
class_weights = compute_class_weight(
    'balanced',
    classes=np.unique(train_batches.classes),
    y=train_batches.classes
)
class_weights = dict(enumerate(class_weights))
print("Class weights:", class_weights)


# ====================== FEATURE EXTRACTOR ======================
img_size = (300, 300)

# Build EfficientNet-B3 model
base_model = tf.keras.applications.EfficientNetB3(
    weights='imagenet',
    include_top=False,
    input_shape=(img_size[0], img_size[1], 3)
)

# Freeze base model layers
base_model.trainable = False


x = base_model.output       # Output from base model                                           
x = tf.keras.layers.GlobalAveragePooling2D(name="avg_pool")(x)     # Reduce spatial dimensions to single vector
x = tf.keras.layers.Dropout(0.5, name="top_dropout")(x)            # Reduce overfitting by randomly setting 50% inputs to zero
predictions = tf.keras.layers.Dense(1, activation='sigmoid', name="predictions")(x)  # Binary classification output

# Combine base model and custom head
model = tf.keras.Model(inputs=base_model.input, outputs=predictions, name="EfficientNet-B3")

model.summary()

# ====================== CLASSIFICATION MODEL ======================

# # Compile with class weights
model.compile(optimizer='adam',  # Adaptive learning rate optimizer
              loss='binary_crossentropy',  # Suitable for binary classification
              metrics=['accuracy']  # Track accuracy metric
)

# Train initial model
import datetime
# Set up TensorBoard callback with histogram visualization
log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(
    log_dir=log_dir,
    histogram_freq=1,  # Enable histogram computation for weight analysis
    write_graph=True,
    write_images=True,
    update_freq='epoch',
    profile_batch=0
)

early_stopping_callback = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=1e-2,
    patience=5,
    verbose=1,
    restore_best_weights=True
)


epoch = 3
history = model.fit(
    train_batches, 
    validation_data=valid_batches, 
    epochs=epoch, 
    #class_weight=class_weights, 
    callbacks = [tensorboard_callback, early_stopping_callback],
    verbose=1
)

# ====================== GRAD-CAMS  ======================

def make_gradcam_heatmap(img_array, model, last_conv_layer_name='top_activation', pred_index=None):
    """
    Generate heatmap using Grad-CAM technique
    Args:
        img_array: Preprocessed input image (4D array)
        model: Trained Keras model
        last_conv_layer_name: Name of last convolutional layer
        pred_index: Index of predicted class (None for auto-selection)
    Returns:
        Heatmap array highlighting important regions
    """
    # Create gradient model that outputs last conv layer activations and predictions
    grad_model = Model(
        inputs=model.input,
        outputs=[model.get_layer(last_conv_layer_name).output, model.output]
    )
    
    # Compute gradients with TensorFlow's GradientTape
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)  # Forward pass
        if pred_index is None:
            pred_index = tf.argmax(preds[0])  # Get highest probability class
        class_channel = preds[:, pred_index]  # Get prediction score for target class
    
    # Compute gradients of target class score with respect to conv layer output
    grads = tape.gradient(class_channel, last_conv_layer_output)
    
    # Pool gradients across spatial dimensions (global average)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    
    # Compute weighted combination of feature maps
    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)  # Remove single-dimensional entries
    
    # Normalize heatmap between 0-1
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()  # Convert to NumPy array

def overlay_heatmap(original_img, heatmap, alpha=0.4):
    heatmap = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
    overlayed = cv2.addWeighted(original_img, alpha, heatmap, 1 - alpha, 0)
    return overlayed
    
def visualize_generator_samples(generator, num_samples=9):
    """
    Visualize images from a data generator
    
    Args:
        generator: Keras ImageDataGenerator (e.g., val_generator)
        num_samples: Number of images to display (must be perfect square)
    """
    # Get a batch of data
    images, labels = next(generator)
    
    # Get class names from generator
    class_names = list(generator.class_indices.keys())
    
    # Create subplots
    plt.figure(figsize=(10, 10))
    for i in range(min(num_samples, len(images))):
        # Create subplot
        ax = plt.subplot(int(num_samples**0.5), int(num_samples**0.5), i+1)
        
        # Display image (reverse preprocessing)
        img = images[i]
        plt.imshow(img)
        
        # Show true label
        true_class = class_names[int(labels[i])]
        plt.title(f"True: {true_class}")
        plt.axis("off")
    
    plt.tight_layout()
    plt.show()

# Reset generator before visualization (important!)
#valid_batches.reset()
test_batches.reset()

# Visualize validation images
#visualize_generator_samples(valid_batches, num_samples=9)
visualize_generator_samples(test_batches, num_samples=9)
