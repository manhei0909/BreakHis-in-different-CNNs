import os
import math
import random
import shutil
os.environ['TF_CPP_MIN_LOG_LEVLE'] = '2'

import scipy
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sn
import time
from tensorflow.keras.metrics import AUC

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

names = ["benign", "malignant"]

# Load the base VGG16 model (without the final classification layers)
vgg16_model = tf.keras.applications.VGG16(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)

vgg16_model.summary()

model = keras.models.Sequential()
for layer in vgg16_model.layers[0:-1]:
    model.add(layer)
model.summary()

for layer in model.layers:
    layer.trainable = False

model.add(layers.Dense(2))
model.summary()

#vgg16_model.trainable = False  # Freeze the base model's weights

# Summary of the new model
model.summary()


# loss and optimizer
loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)
optim = keras.optimizers.Adam(learning_rate=0.001)
metrics = ["accuracy"]

model.compile(optimizer=optim, loss=loss, metrics=metrics)

# Correct reference to the preprocess_input function for VGG16

preprocess_input = tf.keras.applications.vgg16.preprocess_input

# Generate batches of tensor image data with real-time dataaugmentation
train_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)
          #rotation_range=20,
          #horizontal_flip=True,
          #width_shift_range=0.2,
          #height_shift_range=0.2,
          #shear_range=0.2,
          #zoom_range=0.2)
test_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)
valid_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input)

train_batches = train_gen.flow_from_directory(
  "B:\\Cancer\\BreaKHis 400X\\BreaKHis 400X\\train",
  target_size=(224, 224),
  class_mode='sparse',
  batch_size=32,
  shuffle=True,
  color_mode="rgb",
  classes=names
)

test_batches = train_gen.flow_from_directory(
  "B:\\Cancer\\BreaKHis 400X\\BreaKHis 400X\\test",
  target_size=(224, 224),
  class_mode='sparse',
  batch_size=32,
  shuffle=False,
  color_mode="rgb",
  classes=names
)

valid_batches = train_gen.flow_from_directory(
  "B:\\Cancer\\BreaKHis 400X\\BreaKHis 400X\\valid",
  target_size=(224, 224),
  class_mode='sparse',
  batch_size=32,
  shuffle=False,
  color_mode="rgb",
  classes=names
)

train_batch = train_batches[0]
print(train_batch[0].shape)
print(train_batch[1])
test_batch = test_batches[0]
print(test_batch[0].shape)
print(test_batch[1])

# check the image after augmentation
def show(batch, pred_labels=None):
  plt.figure(figsize=(10,10))
  for i in range(4):
    plt.subplot(2,2,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(batch[0][i], cmap=plt.cm.binary)
    lbl = names[int(batch[1][i])]
    if pred_labels is not None:
      lbl += "/Pred: " + names[int(pred_labels[i])]
    plt.xlabel(lbl)
  plt.show()

show(test_batch)
show(train_batch)

#training
epochs = 30

# callback
early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=2)
log_BC_VGG16 = model.fit(train_batches, validation_data=valid_batches,
                callbacks=[early_stopping],
                epochs=epochs, verbose=2)

model.save("TL_BC_VGG16.keras")

# plot loss and acc
plt.figure(figsize=(16,6))
plt.subplot(1,2,1)
plt.plot(log_BC_VGG16.history['loss'], label='train loss')
plt.plot(log_BC_VGG16.history['val_loss'], label='valid loss')
plt.grid()
plt.legend(fontsize=15)
plt.subplot(1,2,2)
plt.plot(log_BC_VGG16.history['accuracy'], label='train acc')
plt.plot(log_BC_VGG16.history['val_accuracy'], label='valid acc')
plt.grid()
plt.legend(fontsize=15)

model.evaluate(test_batches, verbose=2)

# Get the predictions from the model
start_time = time.time() # inference time
predictions = model.predict(test_batches, verbose=2)  # Predict on the test batches
predictions = tf.nn.softmax(predictions).numpy()  # Apply softmax to get probabilities
end_time = time.time()
print(f"Inference Time: {end_time - start_time:.2f} seconds")

# Get the predicted class for each image
predicted_labels = np.argmax(predictions, axis=1)  # Index of the maximum probability gives the predicted class

# Get the true labels from the test_batches (ground truth)
true_labels = test_batches.classes  # Ground truth labels from the ImageDataGenerator

# Class names (e.g., "Bird-drop", "Clean", etc.)
class_indices = list(test_batches.class_indices.keys())

# Show some sample predictions with their true labels
print("Sample Inference Results:")
for i in range(10):  # Display 10 sample results
    print(f"Image {i + 1}:")
    print(f"  Predicted: {class_indices[predicted_labels[i]]} (Class {predicted_labels[i]})")
    print(f"  True: {class_indices[true_labels[i]]} (Class {true_labels[i]})\n")

# Optionally, plot the first few test images and annotate them with their predictions
plt.figure(figsize=(15, 10))

for batch_idx, (batch_images, batch_labels) in enumerate(test_batches):  
    if batch_idx >= 9:  
        break
    plt.subplot(3, 3, batch_idx + 1)
    img, lbl = batch_images[0], batch_labels[0]  #
    plt.imshow(img)
    plt.title(f"Predicted: {class_indices[predicted_labels[batch_idx]]}\nTrue: {class_indices[int(lbl)]}")
    plt.axis("off")

plt.tight_layout()
plt.show()

def calculate_auc(true_labels, predictions):
  auc_metric = AUC()
  auc_metric.update_state(true_labels, predictions)
  return auc_metric.result().numpy()


# Manual F1-score calculation
def calculate_f1_score(true_labels, predicted_labels):
  true_positive = np.sum((true_labels == predicted_labels) & (true_labels == 1))
  false_positive = np.sum((true_labels != predicted_labels) & (predicted_labels == 1))
  false_negative = np.sum((true_labels != predicted_labels) & (true_labels == 1))
  precision = true_positive / (true_positive + false_positive + 1e-7)
  recall = true_positive / (true_positive + false_negative + 1e-7)
  f1 = 2 * (precision * recall) / (precision + recall + 1e-7)
  return f1


try:
  auc_score = calculate_auc(true_labels, predictions[:, 1])  # Use the second column for positive predictions
  print(f"AUC: {auc_score:.4f}")
except ValueError as e:
  print(f"AUC Calculation Error: {e}")

f1 = calculate_f1_score(true_labels, predicted_labels)
print(f"F1-score: {f1:.4f}")
